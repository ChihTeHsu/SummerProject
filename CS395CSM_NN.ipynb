{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD3gscg9QZ4A",
        "outputId": "f6dca928-3984-4527-be06-49a3828c8b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = pd.read_csv('accepted_2007_to_2018Q4.csv',parse_dates=['issue_d'], infer_datetime_format=True)\n",
        "data.drop(data.tail(2).index, inplace=True)"
      ],
      "metadata": {
        "id": "LExr1nKrAM7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a8f1fb-9853-4c8b-a20a-07e1863f0298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_feat = ['acc_now_delinq','acc_open_past_24mths','all_util','annual_inc','avg_cur_bal','bc_open_to_buy','bc_util',\n",
        "            'chargeoff_within_12_mths','collections_12_mths_ex_med','delinq_2yrs','delinq_amnt','dti','earliest_cr_line',\n",
        "            'fico_range_high','fico_range_low','il_util','inq_fi','inq_last_12m','inq_last_6mths','installment',\n",
        "            'last_fico_range_high','last_fico_range_low','max_bal_bc','mo_sin_old_il_acct','mo_sin_old_rev_tl_op',\n",
        "            'mo_sin_rcnt_rev_tl_op','mo_sin_rcnt_tl','mort_acc','mths_since_last_delinq','mths_since_last_major_derog',\n",
        "            'mths_since_last_record','mths_since_rcnt_il','mths_since_recent_bc','mths_since_recent_bc_dlq',\n",
        "            'mths_since_recent_inq','mths_since_recent_revol_delinq','num_accts_ever_120_pd','num_actv_bc_tl',\n",
        "            'num_actv_rev_tl','num_bc_sats','num_bc_tl','num_il_tl','num_op_rev_tl','num_rev_accts','num_rev_tl_bal_gt_0',\n",
        "            'num_sats','num_tl_120dpd_2m','num_tl_30dpd','num_tl_90g_dpd_24m','num_tl_op_past_12m','open_acc','open_acc_6m',\n",
        "            'open_il_12m','open_il_24m','open_rv_12m','open_rv_24m','pct_tl_nvr_dlq','percent_bc_gt_75','pub_rec',\n",
        "            'pub_rec_bankruptcies','revol_util','tot_coll_amt','tot_cur_bal','tot_hi_cred_lim','total_acc','total_bal_ex_mort',\n",
        "            'total_bal_il','total_bc_limit','total_cu_tl','total_il_high_credit_limit','total_rev_hi_lim']\n",
        "\n",
        "cat_feat = ['term','verification_status','sub_grade']\n",
        "\n",
        "X = data[ ['issue_d'] + cat_feat + num_feat].copy()\n",
        "#X.info()\n",
        "\n",
        "# The features earliest_cr_line is date and its type should be changed to datetime. Later \n",
        "# it need to be transformed to ordinal numeric features\n",
        "X['earliest_cr_line'] = pd.to_numeric(pd.to_datetime(X['earliest_cr_line'], infer_datetime_format=True))\n",
        "\n",
        "#print(data['loan_status'].value_counts())\n",
        "y = data['loan_status'].copy()\n",
        "y = (~y.isin(['Current', 'Fully Paid', 'In Grace Period'])).astype('int')\n",
        "y.value_counts()\n",
        "\n",
        "del data"
      ],
      "metadata": {
        "id": "KVDiI2xqRuKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_feat = X.select_dtypes('object').columns.values\n",
        "print(X[cat_feat].nunique().sort_values())\n",
        "\n",
        "X['term'].replace([' 36 months',' 60 months'], [int(0), int(1)], inplace=True)\n",
        "\n",
        "X['verification_status'].replace(['Not Verified','Source Verified', 'Verified'], [int(0), int(1), int(2)], inplace=True)\n",
        "\n",
        "X['sub_grade'].replace(['A1','A2','A3','A4','A5','B1','B2','B3','B4','B5','C1','C2','C3','C4','C5',\n",
        "                        'D1','D2','D3','D4','D5','E1','E2','E3','E4','E5','F1','F2','F3','F4','F5',\n",
        "                        'G1','G2','G3','G4','G5'], [int(x) for x in range(35)], inplace=True)\n",
        "\n",
        "#%%\n",
        "print(X.shape)\n",
        "\n",
        "idx = np.where(\n",
        "    (X['annual_inc'] <= 250000) & (X['dti'] <= 50) & (X['open_acc'] <= 40) &\n",
        "    (X['total_acc'] <= 80) & (X['revol_util'] <= 120) & (X['earliest_cr_line'] > -2E18)\n",
        "    )[0]\n",
        "X = X.iloc[idx]\n",
        "y = y.iloc[idx]\n",
        "print(X.shape)\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=0)\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, random_state=0)\n",
        "\n",
        "idx = np.where(X['issue_d'].dt.year < 2017.)[0]\n",
        "X_train = X.iloc[idx].drop('issue_d', axis='columns')\n",
        "y_train = y.iloc[idx]\n",
        "\n",
        "idx = np.where( (X['issue_d'].dt.year == 2017.)&(X['issue_d'].dt.month < 8.) )[0]\n",
        "X_val = X.iloc[idx].drop('issue_d', axis='columns')\n",
        "y_val = y.iloc[idx]\n",
        "\n",
        "idx = np.where( ((X['issue_d'].dt.year == 2017.)&(X['issue_d'].dt.month >= 8.))|(X['issue_d'].dt.year >= 2018.) )[0]\n",
        "X_test = X.iloc[idx].drop('issue_d', axis='columns')\n",
        "y_test = y.iloc[idx]\n",
        "\n",
        "print('Training prob Bad',np.mean(y_train))\n",
        "print('Validation prob Bad',np.mean(y_val))\n",
        "print('Test prob Bad',np.mean(y_test))\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbbxMh76Rvw7",
        "outputId": "5113f76c-66e6-4f74-8688-e447dcf0c812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "term                    2\n",
            "verification_status     3\n",
            "sub_grade              35\n",
            "dtype: int64\n",
            "(2260699, 75)\n",
            "(2213429, 75)\n",
            "Training prob Bad 0.1750958388833793\n",
            "Validation prob Bad 0.12304089505846083\n",
            "Test prob Bad 0.05269638093425369\n",
            "(1304794, 74)\n",
            "(236141, 74)\n",
            "(672494, 74)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "def _prepare_labels_logits_weights(labels, logits, weights):\n",
        "    \"\"\"Validates labels, logits, and weights.\n",
        "    Converts inputs to tensors, checks shape compatibility, and casts dtype if\n",
        "    necessary.\n",
        "\n",
        "    Args:\n",
        "      labels: A `Tensor` of shape [batch_size] or [batch_size, num_labels].\n",
        "\n",
        "      logits: A `Tensor` with the same shape as `labels`.\n",
        "\n",
        "      weights: Either `None` or a `Tensor` with shape broadcastable to `logits`.\n",
        "\n",
        "    Returns:\n",
        "      labels: Same as `labels` arg after possible conversion to tensor, cast, and\n",
        "        reshape.\n",
        "\n",
        "      logits: Same as `logits` arg after possible conversion to tensor and\n",
        "        reshape.\n",
        "\n",
        "      weights: Same as `weights` arg after possible conversion, cast, and reshape.\n",
        "\n",
        "      original_shape: Shape of `labels` and `logits` before reshape.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: If `labels` and `logits` do not have the same shape.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert `labels` and `logits` to Tensors and standardize dtypes.\n",
        "    logits = tf.convert_to_tensor(logits, name='logits')\n",
        "    labels = tf.cast(tf.convert_to_tensor(labels, name='labels'), dtype=logits.dtype.base_dtype)\n",
        "    weights = tf.cast(tf.convert_to_tensor(weights, name='weights'), dtype=logits.dtype.base_dtype)\n",
        "\n",
        "    try:\n",
        "        labels.get_shape().merge_with(logits.get_shape())\n",
        "    except ValueError:\n",
        "        raise ValueError('logits and labels must have the same shape (%s vs %s)' %\n",
        "                       (logits.get_shape(), labels.get_shape()))\n",
        "\n",
        "    original_shape = labels.get_shape().as_list()\n",
        "\n",
        "    if labels.get_shape().ndims > 0:\n",
        "        original_shape[0] = -1\n",
        "\n",
        "    if labels.get_shape().ndims <= 1:\n",
        "        labels = tf.reshape(labels, [-1, 1])\n",
        "        logits = tf.reshape(logits, [-1, 1])\n",
        "\n",
        "    if weights.get_shape().ndims == 1:\n",
        "        # Weights has shape [batch_size]. Reshape to [batch_size, 1].\n",
        "        weights = tf.reshape(weights, [-1, 1])\n",
        "\n",
        "    if weights.get_shape().ndims == 0:\n",
        "        # Weights is a scalar. Change shape of weights to match logits.\n",
        "        weights *= tf.ones_like(logits)\n",
        "\n",
        "    return labels, logits, weights, original_shape\n",
        "\n",
        "def roc_auc_loss(\n",
        "    labels,\n",
        "    logits,\n",
        "    weights=1.0,\n",
        "    surrogate_type='xent',\n",
        "    scope=None):\n",
        "\n",
        "    with tf.name_scope(\"roc_auc\"):\n",
        "        # Convert inputs to tensors and standardize dtypes.\n",
        "        labels, logits, weights, original_shape = _prepare_labels_logits_weights(labels, logits, weights)\n",
        "        \n",
        "        # Create tensors of pairwise differences for logits and labels, and\n",
        "        # pairwise products of weights. These have shape\n",
        "        # [batch_size, batch_size, num_labels].\n",
        "        logits_difference = tf.expand_dims(logits, 0) - tf.expand_dims(logits, 1)\n",
        "        labels_difference = tf.expand_dims(labels, 0) - tf.expand_dims(labels, 1)\n",
        "        weights_product = tf.expand_dims(weights, 0) * tf.expand_dims(weights, 1)\n",
        "\n",
        "        signed_logits_difference = labels_difference * logits_difference\n",
        "\n",
        "        raw_loss = weighted_surrogate_loss(labels=tf.ones_like(signed_logits_difference),\n",
        "                                           logits=signed_logits_difference,\n",
        "                                           surrogate_type=surrogate_type)\n",
        "        \n",
        "        weighted_loss = weights_product * raw_loss\n",
        "\n",
        "        # Zero out entries of the loss where labels_difference zero (so loss is only\n",
        "        # computed on pairs with different labels).\n",
        "        loss = tf.reduce_mean(tf.abs(labels_difference) * weighted_loss, 0) * 0.5\n",
        "        loss = tf.reshape(loss, original_shape)\n",
        "        return loss\n",
        "\n",
        "def weighted_surrogate_loss(labels,\n",
        "                            logits,\n",
        "                            surrogate_type='xent',\n",
        "                            positive_weights=1.0,\n",
        "                            negative_weights=1.0,\n",
        "                            name=None):\n",
        "    \"\"\"Returns either weighted cross-entropy or hinge loss.\n",
        "    For example `surrogate_type` is 'xent' returns the weighted cross\n",
        "    entropy loss.\n",
        "\n",
        "    Args:\n",
        "     labels: A `Tensor` of type `float32` or `float64`. Each entry must be\n",
        "        between 0 and 1. `labels` can be a 2D tensor with shape\n",
        "        [batch_size, num_labels] or a 3D tensor with shape\n",
        "        [batch_size, num_labels, K].\n",
        "\n",
        "      logits: A `Tensor` of the same type and shape as `labels`. If `logits` has\n",
        "        shape [batch_size, num_labels, K], each slice [:, :, k] represents an\n",
        "        'attempt' to predict `labels` and the loss is computed per slice.\n",
        "\n",
        "      surrogate_type: A string that determines which loss to return, supports\n",
        "      'xent' for cross-entropy and 'hinge' for hinge loss.\n",
        "\n",
        "      positive_weights: A `Tensor` that holds positive weights and has the\n",
        "        following semantics according to its shape:\n",
        "          scalar - A global positive weight.\n",
        "          1D tensor - must be of size K, a weight for each 'attempt'\n",
        "          2D tensor - of size [num_labels, K'] where K' is either K or 1.\n",
        "        The `positive_weights` will be expanded to the left to match the\n",
        "        dimensions of logits and labels.\n",
        "\n",
        "      negative_weights: A `Tensor` that holds positive weight and has the\n",
        "        semantics identical to positive_weights.\n",
        "\n",
        "      name: A name for the operation (optional).\n",
        "\n",
        "    Returns:\n",
        "      The weigthed loss.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: If value of `surrogate_type` is not supported.\n",
        "    \"\"\"\n",
        "\n",
        "    with tf.name_scope('weighted_loss'):\n",
        "        if surrogate_type == 'xent':\n",
        "            return weighted_sigmoid_cross_entropy_with_logits(\n",
        "                logits=logits,\n",
        "                labels=labels,\n",
        "                positive_weights=positive_weights,\n",
        "                negative_weights=negative_weights,\n",
        "                name=name)\n",
        "        elif surrogate_type == 'hinge':\n",
        "            return weighted_hinge_loss(\n",
        "                logits=logits,\n",
        "                labels=labels,\n",
        "                positive_weights=positive_weights,\n",
        "                negative_weights=negative_weights,\n",
        "                name=name)\n",
        "        raise ValueError('surrogate_type %s not supported.' % surrogate_type) \n",
        "\n",
        "def weighted_sigmoid_cross_entropy_with_logits(labels,\n",
        "                                               logits,\n",
        "                                               positive_weights=1.0,\n",
        "                                               negative_weights=1.0,\n",
        "                                               name=None):\n",
        "    \"\"\"Computes a weighting of sigmoid cross entropy given `logits`.\n",
        "    Measures the weighted probability error in discrete classification tasks in\n",
        "    which classes are independent and not mutually exclusive.  For instance, one\n",
        "    could perform multilabel classification where a picture can contain both an\n",
        "    elephant and a dog at the same time. The class weight multiplies the\n",
        "    different types of errors.\n",
        "    For brevity, let `x = logits`, `z = labels`, `c = positive_weights`,\n",
        "    `d = negative_weights`  The\n",
        "\n",
        "    weighed logistic loss is\n",
        "    ```\n",
        "    c * z * -log(sigmoid(x)) + d * (1 - z) * -log(1 - sigmoid(x))\n",
        "    = c * z * -log(1 / (1 + exp(-x))) - d * (1 - z) * log(exp(-x) / (1 + exp(-x)))\n",
        "    = c * z * log(1 + exp(-x)) + d * (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n",
        "    = c * z * log(1 + exp(-x)) + d * (1 - z) * (x + log(1 + exp(-x)))\n",
        "    = (1 - z) * x * d + (1 - z + c * z ) * log(1 + exp(-x))\n",
        "    =  - d * x * z + d * x + (d - d * z + c * z ) * log(1 + exp(-x))\n",
        "    ```\n",
        "    To ensure stability and avoid overflow, the implementation uses the identity\n",
        "        log(1 + exp(-x)) = max(0,-x) + log(1 + exp(-abs(x)))\n",
        "\n",
        "    and the result is computed as\n",
        "      ```\n",
        "      = -d * x * z + d * x\n",
        "        + (d - d * z + c * z ) * (max(0,-x) + log(1 + exp(-abs(x))))\n",
        "      ```\n",
        "    Note that the loss is NOT an upper bound on the 0-1 loss, unless it is divided\n",
        "    by log(2).\n",
        "\n",
        "    Args:\n",
        "      labels: A `Tensor` of type `float32` or `float64`. `labels` can be a 2D\n",
        "        tensor with shape [batch_size, num_labels] or a 3D tensor with shape\n",
        "        [batch_size, num_labels, K].\n",
        "\n",
        "      logits: A `Tensor` of the same type and shape as `labels`. If `logits` has\n",
        "        shape [batch_size, num_labels, K], the loss is computed separately on each\n",
        "        slice [:, :, k] of `logits`.\n",
        "\n",
        "      positive_weights: A `Tensor` that holds positive weights and has the\n",
        "        following semantics according to its shape:\n",
        "          scalar - A global positive weight.\n",
        "          1D tensor - must be of size K, a weight for each 'attempt'\n",
        "          2D tensor - of size [num_labels, K'] where K' is either K or 1.\n",
        "        The `positive_weights` will be expanded to the left to match the\n",
        "        dimensions of logits and labels.\n",
        "\n",
        "      negative_weights: A `Tensor` that holds positive weight and has the\n",
        "        semantics identical to positive_weights.\n",
        "\n",
        "      name: A name for the operation (optional).\n",
        "\n",
        "    Returns:\n",
        "      A `Tensor` of the same shape as `logits` with the componentwise\n",
        "        weighted logistic losses.\n",
        "    \"\"\"\n",
        "\n",
        "    with tf.name_scope('weighted_logistic_loss'):\n",
        "        labels, logits, positive_weights, negative_weights = prepare_loss_args(labels, logits, positive_weights, negative_weights)\n",
        "\n",
        "        softplus_term = tf.add(tf.maximum(-logits, 0.0), tf.math.log(1.0 + tf.exp(-tf.abs(logits))))\n",
        "        weight_dependent_factor = ( negative_weights + (positive_weights - negative_weights) * labels)\n",
        "        return (negative_weights * (logits - labels * logits) + weight_dependent_factor * softplus_term)\n",
        "\n",
        "def weighted_hinge_loss(labels,\n",
        "                        logits,\n",
        "                        positive_weights=1.0,\n",
        "                        negative_weights=1.0,\n",
        "                        name=None):\n",
        "    \"\"\"Computes weighted hinge loss given logits `logits`.\n",
        "    The loss applies to multi-label classification tasks where labels are\n",
        "    independent and not mutually exclusive. See also\n",
        "    `weighted_sigmoid_cross_entropy_with_logits`.\n",
        "\n",
        "    Args:\n",
        "      labels: A `Tensor` of type `float32` or `float64`. Each entry must be\n",
        "        either 0 or 1. `labels` can be a 2D tensor with shape\n",
        "        [batch_size, num_labels] or a 3D tensor with shape\n",
        "        [batch_size, num_labels, K].\n",
        "\n",
        "      logits: A `Tensor` of the same type and shape as `labels`. If `logits` has\n",
        "        shape [batch_size, num_labels, K], the loss is computed separately on each\n",
        "        slice [:, :, k] of `logits`.\n",
        "      \n",
        "      positive_weights: A `Tensor` that holds positive weights and has the\n",
        "        following semantics according to its shape:\n",
        "          scalar - A global positive weight.\n",
        "          1D tensor - must be of size K, a weight for each 'attempt'\n",
        "          2D tensor - of size [num_labels, K'] where K' is either K or 1.\n",
        "        The `positive_weights` will be expanded to the left to match the\n",
        "        dimensions of logits and labels.\n",
        "      \n",
        "      negative_weights: A `Tensor` that holds positive weight and has the\n",
        "        semantics identical to positive_weights.\n",
        "      \n",
        "      name: A name for the operation (optional).\n",
        "    Returns:\n",
        "      A `Tensor` of the same shape as `logits` with the componentwise\n",
        "        weighted hinge loss.\n",
        "    \"\"\"\n",
        "\n",
        "    with tf.name_scope(\"weighted_hinge_loss\"):\n",
        "        labels, logits, positive_weights, negative_weights = prepare_loss_args(labels, logits, positive_weights, negative_weights)\n",
        "\n",
        "        positives_term = positive_weights * labels * tf.maximum(1.0 - logits, 0)\n",
        "        negatives_term = (negative_weights * (1.0 - labels) * tf.maximum(1.0 + logits, 0))\n",
        "        return positives_term + negatives_term\n",
        "\n",
        "def prepare_loss_args(labels, logits, positive_weights, negative_weights):\n",
        "    \"\"\"Prepare arguments for weighted loss functions.\n",
        "    If needed, will convert given arguments to appropriate type and shape.\n",
        "    Args:\n",
        "      labels: labels or labels of the loss function.\n",
        "      logits: Logits of the loss function.\n",
        "      positive_weights: Weight on the positive examples.\n",
        "      negative_weights: Weight on the negative examples.\n",
        "    Returns:\n",
        "      Converted labels, logits, positive_weights, negative_weights.\n",
        "    \"\"\"\n",
        "\n",
        "    logits = tf.convert_to_tensor(logits, name='logits')\n",
        "    #labels = convert_and_cast(labels, 'labels', logits.dtype)\n",
        "    labels = tf.cast(tf.convert_to_tensor(labels, name='labels'), dtype=logits.dtype)\n",
        "\n",
        "    if len(labels.get_shape()) == 2 and len(logits.get_shape()) == 3:\n",
        "        labels = tf.expand_dims(labels, [2])\n",
        "\n",
        "    positive_weights = tf.cast(tf.convert_to_tensor(positive_weights, name='positive_weights'), dtype=logits.dtype)\n",
        "    positive_weights = expand_outer(positive_weights, logits.get_shape().ndims)\n",
        "    \n",
        "    negative_weights = tf.cast(tf.convert_to_tensor(negative_weights, name='negative_weights'), dtype=logits.dtype)\n",
        "    negative_weights = expand_outer(negative_weights, logits.get_shape().ndims)\n",
        "    return labels, logits, positive_weights, negative_weights\n",
        "\n",
        "def expand_outer(tensor, rank):\n",
        "    \"\"\"Expands the given `Tensor` outwards to a target rank.\n",
        "    For example if rank = 3 and tensor.shape is [3, 4], this function will expand\n",
        "    to such that the resulting shape will be  [1, 3, 4].\n",
        "    Args:\n",
        "      tensor: The tensor to expand.\n",
        "      rank: The target dimension.\n",
        "    Returns:\n",
        "      The expanded tensor.\n",
        "    Raises:\n",
        "      ValueError: If rank of `tensor` is unknown, or if `rank` is smaller than\n",
        "        the rank of `tensor`.\n",
        "    \"\"\"\n",
        "\n",
        "    if tensor.get_shape().ndims is None:\n",
        "        raise ValueError('tensor dimension must be known.')\n",
        "    if len(tensor.get_shape()) > rank:\n",
        "        raise ValueError('`rank` must be at least the current tensor dimension: (%s vs %s).' % (rank, len(tensor.get_shape())))\n",
        "    while len(tensor.get_shape()) < rank:\n",
        "        tensor = tf.expand_dims(tensor, 0)\n",
        "    return tensor\n",
        "\n",
        "class BatchNormFCLayer(tf.keras.layers.Layer):  # for the case of fully connected (1D inputs)\n",
        "    \"\"\"\n",
        "    We create class variables such as gamma and beta to be trained. Also creating pop_mean and pop_var\n",
        "    that are expected to grow up to obtain estimates for the population mean and population variance.\n",
        "    The exponential moving average is simple and lets us avoid extra work than moving average.\n",
        "    It is known that the α of the EMA is associated with window length n like this: α =2/(n+1)\n",
        "    \"\"\"\n",
        "    def __init__(self, decay = 0.999, epsilon=0.00000001):\n",
        "        \"\"\"\n",
        "        :param epsilon:\n",
        "        :param decay:\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        gamma_init = tf.ones_initializer()\n",
        "        self.gamma = tf.Variable(initial_value=gamma_init(shape=[1], dtype='float32'), trainable=True)\n",
        "       \n",
        "        beta_init = tf.zeros_initializer()\n",
        "        self.beta = tf.Variable(initial_value=beta_init(shape=[1], dtype='float32'), trainable=True)\n",
        "       \n",
        "        self.decay = decay\n",
        "        self.epsilon = epsilon\n",
        "    \"\"\"\n",
        "    In general, we might need to know the shape of the input before runtime in which case we can implement\n",
        "    the build() method in our layer which takes input_shape as a parameter and is called when we compile.\n",
        "    \"\"\"\n",
        "    def build(self, input_shape):  # should pass shape for our variable\n",
        "        self.pop_mean = tf.Variable(tf.zeros([input_shape[-1]]), trainable=False)\n",
        "        self.pop_var = tf.Variable(tf.ones([input_shape[-1]]), trainable=False)\n",
        "        super().build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, mask=None, training=None):  # Defines the computation from inputs to outputs\n",
        "        \"\"\"\n",
        "        DON'T USE 'training=True' when built by Functional API. If doing that then we force the layer be in\n",
        "        the training mode even during the inference.\n",
        "        Example:\n",
        "        inputs = tf.keras.Input(shape=(10))\n",
        "        x = tf.keras.layers.Dropout(rate=0.5)(inputs, training=True) #<- take training=True out makes inference correct\n",
        "        model = tf.keras.Model(inputs=inputs,outputs=x)\n",
        "        model.predict(tf.constant([1]*10))\n",
        "        \"\"\"\n",
        "        if mask is None:\n",
        "            mask = tf.ones_like(inputs)\n",
        "        prob_mask = tf.math.divide_no_nan(mask, tf.math.reduce_sum( mask, axis=0 ))  # Mask: real value = 1, NaN value = 0\n",
        "\n",
        "        mu = tf.math.reduce_sum( tf.math.multiply_no_nan(inputs, prob_mask) , axis=0 )\n",
        "        variance = tf.math.reduce_sum( tf.math.multiply_no_nan( inputs**2, prob_mask) , axis=0 ) - mu ** 2\n",
        "\n",
        "        if training:  # In case of training, perform batch normalization to learn beta and gamma\n",
        "            self.pop_mean.assign( self.pop_mean * self.decay + mu * (1 - self.decay) )\n",
        "            self.pop_var.assign( self.pop_var * self.decay + variance * (1 - self.decay) )\n",
        "            #outputs = tf.nn.batch_normalization(inputs, mu, variance, self.beta, self.gamma, K.epsilon())\n",
        "            x_hat = (inputs - mu)/tf.sqrt(tf.maximum(variance, K.epsilon()))\n",
        "           \n",
        "        else:  # In case of testing - calculation of the inference model\n",
        "            #outputs = tf.nn.batch_normalization(inputs, self.pop_mean, self.pop_var, self.beta, self.gamma, K.epsilon())\n",
        "            x_hat = (inputs - self.pop_mean)/tf.sqrt(tf.maximum(self.pop_var, K.epsilon()))\n",
        "           \n",
        "        x_hat = tf.math.multiply_no_nan(x_hat, mask) # put non-real value to zeros\n",
        "        outputs = self.gamma * x_hat + self.beta # + (mask-1)*9 # replace non-real value\n",
        "        return outputs\n",
        "\n",
        "class GBN(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Ghost Batch Normalization\n",
        "    https://arxiv.org/abs/1705.08741\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size, virtual_batch_size, decay=0.999):\n",
        "        super(GBN, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.virtual_batch_size = virtual_batch_size\n",
        "        self.num_splits = int(np.ceil(self.batch_size / self.virtual_batch_size))\n",
        "        self.bn = BatchNormFCLayer(decay)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.bn.build(input_shape)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs, mask=None, training=None):\n",
        "        if tf.math.floor(tf.shape(inputs)[0] / self.virtual_batch_size)< self.num_splits:\n",
        "            if mask is None:\n",
        "                res = self.bn(inputs, None, training)\n",
        "            else:\n",
        "                res = self.bn(inputs, mask, training)\n",
        "            output = res\n",
        "        else:\n",
        "            inp_chunks = tf.split(inputs, self.num_splits, axis=0)\n",
        "            if mask is None:\n",
        "                res = [self.bn(x_, None, training) for x_ in inp_chunks]\n",
        "            else:\n",
        "                mask_chunks = tf.split(mask, self.num_splits, axis=0)\n",
        "                res = [self.bn(x_, m_, training) for x_, m_ in zip(inp_chunks, mask_chunks)]\n",
        "            output = tf.concat(res, axis=0)\n",
        "        \n",
        "        return output\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "    Args:\n",
        "        q: query shape == [..., seq_len_q, depth]\n",
        "        k: key shape == [..., seq_len_k, depth]\n",
        "        v: value shape == [..., seq_len_v, depth_v]\n",
        "        mask: Float tensor with shape broadcastable to [..., seq_len_q, seq_len_k].\n",
        "    \n",
        "    Returns:\n",
        "        output, attention_weights\n",
        "    \"\"\"\n",
        "    \n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "    \n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "    \n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "    \n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # [..., seq_len_q, seq_len_k]\n",
        "    output = tf.matmul(attention_weights, v)  # [..., seq_len_q, depth_v]\n",
        "    return output, attention_weights\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, output_dim):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        assert d_model % self.num_heads == 0\n",
        "        \n",
        "        self.depth = d_model // self.num_heads\n",
        "        \n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "        self.dense = tf.keras.layers.Dense(output_dim)\n",
        "    \n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into [num_heads, depth].\n",
        "        Transpose the result such that the shape is [batch_size, num_heads, seq_len, depth]\n",
        "        \"\"\"\n",
        "        # [batch_size, seq_len, num_heads, depth]\n",
        "        x = tf.reshape(x, shape=(batch_size, -1, self.num_heads, self.depth)) \n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask=None):\n",
        "        batch_size = tf.shape(q)[0]  # q.shape: [batch_size, seq_len, d_model]\n",
        "        \n",
        "        q = self.wq(q)  # [batch_size, seq_len, d_model]\n",
        "        k = self.wk(k)  # [batch_size, seq_len, d_model]\n",
        "        v = self.wv(v)  # [batch_size, seq_len, d_model]\n",
        "        \n",
        "        q = self.split_heads(q, batch_size)  # [batch_size, num_heads, seq_len_q, depth]\n",
        "        k = self.split_heads(k, batch_size)  # [batch_size, num_heads, seq_len_k, depth]\n",
        "        v = self.split_heads(v, batch_size)  # [batch_size, num_heads, seq_len_v, depth]\n",
        "        \n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "        \n",
        "        # scaled_attention.shape == [batch_size, num_heads, seq_len_q, depth]\n",
        "        # attention_weights.shape == [batch_size, num_heads, seq_len_q, seq_len_k]\n",
        "        \n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "        # [batch_size, seq_len_q, num_heads, depth]\n",
        "        concat_attention = tf.reshape(scaled_attention, shape=(batch_size, -1, self.d_model)) \n",
        "        # [batch_size, seq_len_q, d_model]\n",
        "        \n",
        "        output = self.dense(concat_attention)  # [batch_size, seq_len_q, output_dim]\n",
        "        return output, attention_weights\n",
        "\n",
        "import enum\n",
        "import math\n",
        "class _TokenInitialization(enum.Enum):\n",
        "    UNIFORM = 'uniform'\n",
        "    NORMAL = 'normal'\n",
        "\n",
        "    @classmethod\n",
        "    def from_str(cls, initialization: str) -> '_TokenInitialization':\n",
        "        try:\n",
        "            return cls(initialization)\n",
        "        except ValueError:\n",
        "            valid_values = [x.value for x in _TokenInitialization]\n",
        "            raise ValueError(f'initialization must be one of {valid_values}')\n",
        "    \n",
        "    def apply(self, n_features: int, d_token: int) -> tf.Variable:\n",
        "        d_sqrt_inv = 1 / math.sqrt(d_token)\n",
        "        if self == _TokenInitialization.UNIFORM:\n",
        "            # used in the paper \"Revisiting Deep Learning Models for Tabular Data\";\n",
        "            # is equivalent to `nn.init.kaiming_uniform_(x, a=math.sqrt(5))` (which is\n",
        "            # used by torch to initialize nn.Linear.weight, for example)\n",
        "            initializer = tf.random_uniform_initializer(minval=-d_sqrt_inv, maxval=d_sqrt_inv)\n",
        "            return tf.Variable(initial_value=initializer(shape=(n_features, d_token), dtype=\"float32\"),trainable=True,)\n",
        "            #nn.init.uniform_(x, a=-d_sqrt_inv, b=d_sqrt_inv)\n",
        "        elif self == _TokenInitialization.NORMAL:\n",
        "            #nn.init.normal_(x, std=d_sqrt_inv)\n",
        "            initializer = tf.random_normal_initializer(stddev=d_sqrt_inv)\n",
        "            return tf.Variable(initial_value=initializer(shape=(n_features, d_token), dtype=\"float32\"),trainable=True,)\n",
        "\n",
        "class NumericalFeatureTokenizer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "            self,\n",
        "            n_features: int,\n",
        "            d_token: int,\n",
        "            bias: bool,\n",
        "            initialization: str,\n",
        "            ) -> None:\n",
        "        super(NumericalFeatureTokenizer, self).__init__()\n",
        "        \n",
        "        initialization_ = _TokenInitialization.from_str(initialization)\n",
        "        \n",
        "        self.weight = initialization_.apply(n_features, d_token)\n",
        "        self.bias = initialization_.apply(n_features, d_token) if bias else None\n",
        "    \n",
        "    @property\n",
        "    def n_tokens(self) -> int:\n",
        "        \"\"\"The number of tokens.\"\"\"\n",
        "        return self.weight.shape[0]\n",
        "\n",
        "    @property\n",
        "    def d_token(self) -> int:\n",
        "        \"\"\"The size of one token.\"\"\"\n",
        "        return self.weight.shape[1]\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.weight[None] * x[..., None]\n",
        "        if self.bias is not None:\n",
        "            x = x + self.bias[None]\n",
        "        return x\n",
        "\n",
        "from typing import List\n",
        "class CategoricalFeatureTokenizer(tf.keras.layers.Layer):    \n",
        "    def __init__(\n",
        "            self,\n",
        "            cardinalities: List[int],\n",
        "            d_token: int,\n",
        "            bias: bool,\n",
        "            initialization: str,\n",
        "            ) -> None:\n",
        "        super(CategoricalFeatureTokenizer, self).__init__()\n",
        "        \n",
        "        assert cardinalities, 'cardinalities must be non-empty'\n",
        "        assert d_token > 0, 'd_token must be positive'\n",
        "        initialization_ = _TokenInitialization.from_str(initialization)\n",
        "\n",
        "        self.category_offsets = tf.Variable(tf.cast(tf.cumsum([0]+cardinalities[:-1], axis=0),\"float32\"), trainable=False)\n",
        "        self.embeddings = tf.keras.layers.Embedding(sum(cardinalities), d_token, \n",
        "                                                    embeddings_regularizer=tf.keras.regularizers.L1(0.05),\n",
        "                                                    embeddings_initializer=initialization)\n",
        "        #self.embeddings = tf.keras.layers.Embedding(sum(cardinalities), d_token, embeddings_initializer=tf.keras.initializers.Orthogonal)\n",
        "        self.bias = initialization_.apply(len(cardinalities), d_token) if bias else None\n",
        "    \n",
        "    @property\n",
        "    def n_tokens(self) -> int:\n",
        "        \"\"\"The number of tokens.\"\"\"\n",
        "        return self.category_offsets.shape[0]\n",
        "\n",
        "    @property\n",
        "    def d_token(self) -> int:\n",
        "        \"\"\"The size of one token.\"\"\"\n",
        "        return self.embeddings.output_dim\n",
        "    \n",
        "    def call(self, x):\n",
        "        x = self.embeddings(x + self.category_offsets[None])\n",
        "        if self.bias is not None:\n",
        "            x = x + self.bias[None]\n",
        "        return x"
      ],
      "metadata": {
        "id": "1jGFoEXTlUkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, d_model, num_heads, ff_dim, rate=0.):\n",
        "        super(EncBlock, self).__init__()\n",
        "        #self.att = MultiHeadAttention(d_model=d_model, num_heads=num_heads, output_dim=embed_dim)\n",
        "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model, dropout=rate)\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(ff_dim, activation=\"leaky_relu\"),\n",
        "            tf.keras.layers.Dense(embed_dim),\n",
        "        ])\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        #attn_output, _ = self.att(inputs, inputs, inputs)\n",
        "        attn_output = self.att(inputs, inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "VARLEN = X_train.shape[1] # Variable size for each sample\n",
        "EMBED_DIM = 16\n",
        "D_MODEL = 16\n",
        "NUM_HEADS = 1  # Number of attention heads\n",
        "FF_DIM = 16\n",
        "DECAY = 0.999\n",
        "BATCH_SIZE = 2048\n",
        "VIRTUAL_BATCH = 32\n",
        "\n",
        "CARDINALITIES = [2 for _ in range(VARLEN)] # category size for each variable\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(VARLEN))\n",
        "mask = tf.where( tf.math.is_nan(inputs), 0., 1. ) # w/ real value = 1, w/o real value = 0\n",
        "#n_token = tf.expand_dims(BatchNormFCLayer(decay=DECAY)(inputs, mask), -1)\n",
        "#c_token = CategoricalFeatureTokenizer(CARDINALITIES, EMBED_DIM-1, True, 'uniform')(mask)\n",
        "\n",
        "#n_token = BatchNormFCLayer(decay=DECAY)(inputs, mask)\n",
        "n_token = GBN(BATCH_SIZE, VIRTUAL_BATCH, decay=DECAY)(inputs, mask)\n",
        "n_token = NumericalFeatureTokenizer(VARLEN, 8, True, 'uniform')(n_token)\n",
        "c_token = CategoricalFeatureTokenizer(CARDINALITIES, EMBED_DIM-8, True, 'uniform')(mask)\n",
        "x = tf.concat([n_token, c_token], axis=2)\n",
        "\n",
        "x = EncBlock(EMBED_DIM, D_MODEL, NUM_HEADS, FF_DIM)(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(512, activation=\"leaky_relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dense(32, activation=\"leaky_relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dense(4, activation=\"leaky_relu\")(x)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, amsgrad=True),\n",
        "              #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              loss=roc_auc_loss,\n",
        "              metrics=[tf.keras.metrics.AUC(from_logits=True)])\n",
        "\n",
        "import tempfile\n",
        "tempdir = tempfile.TemporaryDirectory()\n",
        "checkpoint_filepath = f\"{tempdir.name}/_test/ckp\"\n",
        "\n",
        "hist = model.fit(X_train,\n",
        "                 y_train,\n",
        "                 validation_data = (X_val,\n",
        "                                    y_val),\n",
        "                 epochs = 30,\n",
        "                 batch_size = BATCH_SIZE,\n",
        "                 shuffle = True,\n",
        "                 callbacks=[\n",
        "                     tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,save_weights_only=True,monitor='val_loss',verbose=0,mode='min',save_best_only=True),\n",
        "                     tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2, min_lr=0.00001),\n",
        "                     tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "                 ] )\n",
        "\n",
        "model.load_weights( tf.train.latest_checkpoint( f\"{tempdir.name}/_test\" ) )\n",
        "tempdir.cleanup()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAhxBGIkkBIy",
        "outputId": "b20ebdfb-dfbd-4696-da08-f8eff6b1e7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "638/638 [==============================] - 66s 51ms/step - loss: 0.0771 - auc: 0.9223 - val_loss: 0.0200 - val_auc: 0.9550 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0319 - auc: 0.9295 - val_loss: 0.0186 - val_auc: 0.9566 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "638/638 [==============================] - 29s 46ms/step - loss: 0.0311 - auc: 0.9316 - val_loss: 0.0190 - val_auc: 0.9570 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "638/638 [==============================] - 30s 47ms/step - loss: 0.0308 - auc: 0.9327 - val_loss: 0.0188 - val_auc: 0.9569 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "638/638 [==============================] - 30s 47ms/step - loss: 0.0275 - auc: 0.9335 - val_loss: 0.0154 - val_auc: 0.9569 - lr: 5.0000e-04\n",
            "Epoch 6/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0272 - auc: 0.9340 - val_loss: 0.0153 - val_auc: 0.9572 - lr: 5.0000e-04\n",
            "Epoch 7/30\n",
            "638/638 [==============================] - 29s 46ms/step - loss: 0.0270 - auc: 0.9342 - val_loss: 0.0154 - val_auc: 0.9573 - lr: 5.0000e-04\n",
            "Epoch 8/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0269 - auc: 0.9345 - val_loss: 0.0149 - val_auc: 0.9573 - lr: 5.0000e-04\n",
            "Epoch 9/30\n",
            "638/638 [==============================] - 30s 47ms/step - loss: 0.0268 - auc: 0.9345 - val_loss: 0.0153 - val_auc: 0.9571 - lr: 5.0000e-04\n",
            "Epoch 10/30\n",
            "638/638 [==============================] - 29s 46ms/step - loss: 0.0268 - auc: 0.9347 - val_loss: 0.0152 - val_auc: 0.9573 - lr: 5.0000e-04\n",
            "Epoch 11/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0252 - auc: 0.9351 - val_loss: 0.0136 - val_auc: 0.9574 - lr: 2.5000e-04\n",
            "Epoch 12/30\n",
            "638/638 [==============================] - 30s 47ms/step - loss: 0.0251 - auc: 0.9352 - val_loss: 0.0136 - val_auc: 0.9576 - lr: 2.5000e-04\n",
            "Epoch 13/30\n",
            "638/638 [==============================] - 29s 46ms/step - loss: 0.0251 - auc: 0.9353 - val_loss: 0.0137 - val_auc: 0.9575 - lr: 2.5000e-04\n",
            "Epoch 14/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0242 - auc: 0.9355 - val_loss: 0.0128 - val_auc: 0.9574 - lr: 1.2500e-04\n",
            "Epoch 15/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0241 - auc: 0.9356 - val_loss: 0.0128 - val_auc: 0.9575 - lr: 1.2500e-04\n",
            "Epoch 16/30\n",
            "638/638 [==============================] - 30s 47ms/step - loss: 0.0240 - auc: 0.9357 - val_loss: 0.0128 - val_auc: 0.9574 - lr: 1.2500e-04\n",
            "Epoch 17/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0237 - auc: 0.9357 - val_loss: 0.0123 - val_auc: 0.9577 - lr: 6.2500e-05\n",
            "Epoch 18/30\n",
            "638/638 [==============================] - 29s 46ms/step - loss: 0.0236 - auc: 0.9358 - val_loss: 0.0124 - val_auc: 0.9574 - lr: 6.2500e-05\n",
            "Epoch 19/30\n",
            "638/638 [==============================] - 30s 47ms/step - loss: 0.0236 - auc: 0.9358 - val_loss: 0.0124 - val_auc: 0.9575 - lr: 6.2500e-05\n",
            "Epoch 20/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0235 - auc: 0.9356 - val_loss: 0.0121 - val_auc: 0.9574 - lr: 3.1250e-05\n",
            "Epoch 21/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0234 - auc: 0.9358 - val_loss: 0.0121 - val_auc: 0.9574 - lr: 3.1250e-05\n",
            "Epoch 22/30\n",
            "638/638 [==============================] - 30s 47ms/step - loss: 0.0235 - auc: 0.9356 - val_loss: 0.0121 - val_auc: 0.9576 - lr: 3.1250e-05\n",
            "Epoch 23/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0234 - auc: 0.9357 - val_loss: 0.0120 - val_auc: 0.9575 - lr: 1.5625e-05\n",
            "Epoch 24/30\n",
            "638/638 [==============================] - 30s 47ms/step - loss: 0.0233 - auc: 0.9358 - val_loss: 0.0120 - val_auc: 0.9575 - lr: 1.5625e-05\n",
            "Epoch 25/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0233 - auc: 0.9358 - val_loss: 0.0120 - val_auc: 0.9575 - lr: 1.5625e-05\n",
            "Epoch 26/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0232 - auc: 0.9359 - val_loss: 0.0120 - val_auc: 0.9575 - lr: 1.0000e-05\n",
            "Epoch 27/30\n",
            "638/638 [==============================] - 30s 47ms/step - loss: 0.0233 - auc: 0.9356 - val_loss: 0.0120 - val_auc: 0.9575 - lr: 1.0000e-05\n",
            "Epoch 28/30\n",
            "638/638 [==============================] - 29s 46ms/step - loss: 0.0232 - auc: 0.9359 - val_loss: 0.0120 - val_auc: 0.9574 - lr: 1.0000e-05\n",
            "Epoch 29/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0233 - auc: 0.9358 - val_loss: 0.0120 - val_auc: 0.9575 - lr: 1.0000e-05\n",
            "Epoch 30/30\n",
            "638/638 [==============================] - 30s 46ms/step - loss: 0.0233 - auc: 0.9357 - val_loss: 0.0120 - val_auc: 0.9574 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "y_pred = tf.nn.sigmoid(model.predict(X_train, batch_size=BATCH_SIZE))\n",
        "roc_auc = roc_auc_score( y_train, y_pred )\n",
        "print(\"Train\",roc_auc)\n",
        "print(np.mean(y_pred))\n",
        "print(\"\")\n",
        "\n",
        "y_pred = tf.nn.sigmoid(model.predict(X_val, batch_size=BATCH_SIZE))\n",
        "roc_auc = roc_auc_score( y_val, y_pred )\n",
        "print(\"Validation\",roc_auc)\n",
        "print(np.mean(y_pred))\n",
        "print(\"\")\n",
        "\n",
        "y_pred = tf.nn.sigmoid(model.predict(X_test, batch_size=BATCH_SIZE))\n",
        "roc_auc = roc_auc_score( y_test, y_pred )\n",
        "print(\"Testing\",roc_auc)\n",
        "print(np.mean(y_pred))\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "r4AjshjDsgmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d13611-3d49-4cdf-c215-bac847b8707d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "638/638 [==============================] - 10s 13ms/step\n",
            "Train 0.9440108752737824\n",
            "0.46309718\n",
            "\n",
            "116/116 [==============================] - 2s 14ms/step\n",
            "Validation 0.9576556231709001\n",
            "0.3877081\n",
            "\n",
            "329/329 [==============================] - 4s 13ms/step\n",
            "Testing 0.9390306794161319\n",
            "0.30412868\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "False_positive_rate, Recall, thresholds = roc_curve( y_test, y_pred )\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(False_positive_rate, Recall, label='(area = %0.4f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kEkn-0TNsXsH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e8e339ac-28fc-423b-9c68-be9fd636e436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_threshold(threshould, fpr, tpr):\n",
        "   #optimal_idx = np.argmax(tpr - fpr)\n",
        "   optimal_idx = np.argmax(tpr*(1-fpr))\n",
        "   optimal_threshold = threshould[optimal_idx]\n",
        "   # (tpr*(1-fpr)) will be maximum if your fpr is very low and tpr is very high\n",
        "   print(\"the maximum value of tpr*(1-fpr)\", max(tpr*(1-fpr)), \"for threshold\", np.round(optimal_threshold,3))\n",
        "   return optimal_threshold\n",
        "THRESHOLD = find_best_threshold(thresholds, False_positive_rate, Recall)\n",
        "print(THRESHOLD)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-gy-wYZXNAT",
        "outputId": "5ee2b0d7-55e8-409f-c209-e70a41322df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the maximum value of tpr*(1-fpr) 0.7701510568245399 for threshold 0.709\n",
            "0.7093551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, precision_recall_curve\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred_test = (y_pred.numpy() > THRESHOLD).astype('float')\n",
        "\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "prec_test = precision_score(y_test, y_pred_test)\n",
        "rec_test = recall_score(y_test, y_pred_test)\n",
        "print(f'''Accuracy (test): {acc_test:.3f}\n",
        "Precision (test): {prec_test:.3f}\n",
        "Recall (test): {rec_test:.3f}''')\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "ax = sns.heatmap(cm, cmap='viridis_r', annot=True, fmt='d', square=True)\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('True');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "rteSYLkQXRLS",
        "outputId": "b8b71b6b-33ed-4926-b37a-1d912f97be58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (test): 0.918\n",
            "Precision (test): 0.375\n",
            "Recall (test): 0.835\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_weights('/checkpoints/my_checkpoint')"
      ],
      "metadata": {
        "id": "-gt_fezOmBi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-generic-recommended\n",
        "#!jupyter nbconvert --to pdf '/content/drive/MyDrive/Colab Notebooks/CS395T/NN.ipynb'"
      ],
      "metadata": {
        "id": "AknoRTU1YbF7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
