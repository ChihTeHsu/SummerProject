# -*- coding: utf-8 -*-
"""Transformer_IMDB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tGmXZw7Rd_MAya8QtwKmz9tvVbOYN9zm
"""

!pip install prenlp
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

import os
import sys
sys.path.append('/content/gdrive/My Drive/Library/text-classification-transformer')
path_to_file = os.path.join("/content/gdrive/My Drive/Library", "IMDB Dataset.csv")

# IMPORTANT ONLY EXCUTE THIS CELL IF THERE IS NO PRENLP VOCAB FILES
import prenlp
prenlp.data.WikiText103()
!ls .data/wikitext-103/
!python /content/gdrive/MyDrive/Library/text-classification-transformer/vocab.py \
--corpus .data/wikitext-103/wiki.train --prefix wiki --tokenizer sentencepiece --vocab_size 16000

import argparse
args = argparse.ArgumentParser()
args.dataset = 'imdb'
# Input parameters
args.batch_size = 32
args.max_seq_len = 512
# Train parameters
args.epochs = 7
args.lr = 1e-4
args.no_cuda = 'store_true'
# Model parameters
args.hidden = 256
args.n_layers = 6
args.n_attn_heads = 8
args.dropout = 0.1
args.ffn_hidden = 1024

from prenlp.tokenizer import NLTKMosesTokenizer
from torch.utils.data import DataLoader

from data_utils import create_examples
from tokenization import Tokenizer, PretrainedTokenizer
from trainer import Trainer

# Load tokenizer
tokenizer = PretrainedTokenizer(pretrained_model = os.path.join(os.getcwd(),'wiki.model'),
                                vocab_file = os.path.join(os.getcwd(), 'wiki.vocab'))

# Build DataLoader
#train_dataset = create_examples(args, tokenizer, mode='train')
#test_dataset = create_examples(args, tokenizer, mode='test')

# Here we re-impletment the preprocessing
# important we need the previous made Tokenizer model and vocab
import prenlp
DATASETS_CLASSES = {'imdb': prenlp.data.IMDB}
dataset = DATASETS_CLASSES['imdb']()[0] # Only build Train dataset as example !!
print('size of dataset: ', len(dataset))

labels = sorted(list(set([label for _, label in dataset])))
print('labels in original dataset:',labels)
label_dict = {label: i for i, label in enumerate(labels)}
print('creat dictionary of labels',label_dict)

# check the tokenizer padding values == 0
pad_token_id = tokenizer.pad_token_id

# Build up feature and target dataset
features = []
targets = []
for i, (text, label) in enumerate(dataset):
  tokens = tokenizer.tokenize(text)
  tokens = tokens[:args.max_seq_len]

  input_ids = tokenizer.convert_tokens_to_ids(tokens)
  padding_length = args.max_seq_len - len(input_ids)
  input_ids = input_ids + ([pad_token_id] * padding_length) # pad every input text to max_seq_len
  # label to dictionary value is either 0/1 number we need turn it into [0,1]/[1,0] list
  label_id = [0, 0] # initial all zero target list
  label_id[label_dict.get(label)] = 1 # label_id list become [0,1]/[1,0]

  features[len(features):] = [input_ids]
  targets[len(targets):] = [label_id]
  
  if i < 2:
    print(text[:50],': ',label)
    print(tokens[:10])
    print(input_ids[:10],': ',label_id)

import tensorflow as tf
train_examples = tf.data.Dataset.from_tensor_slices((features, targets))
example_input_batch, example_target_batch = next(iter(train_examples))
print(example_input_batch.shape, '\n', example_target_batch.shape)

def filter_max_length(features, targets, max_length=args.max_seq_len):
  return (tf.size(features) <= max_length)

# 訓練集
train_dataset = (train_examples  # 輸出：(中文句子, 英文句子)
                 .filter(lambda x, y: tf.size(x) <= args.max_seq_len) # 將長度超過 MAX_LENGTH 個 tokens 的輸入序列都去掉
                 .cache() # 加快讀取數據
                 .shuffle(15000) # 將例子洗牌確保隨機性
                 .padded_batch(args.batch_size, # 將 batch 裡的序列都 pad 到同樣長度
                               padded_shapes=([args.max_seq_len], # Feature Vector, padded to MAX seq_len.
                                              [2])) # Target vector, padded to numebr of class
                 .prefetch(tf.data.experimental.AUTOTUNE)) # 加速
# 看看最後建立出來的資料集長什麼樣子：
fea_batch, tar_batch = next(iter(train_dataset))
print("feature 索引序列的 batch")
print(fea_batch)
print('-' * 20)
print("target 索引序列的 batch")
print(tar_batch)

from tfTransformer import positional_encoding, EncoderLayer, create_padding_mask

class TransformerEncoderClassifier(tf.keras.Model):
  # Encoder 的初始參數除了本來就要給 EncoderLayer 的參數還多了：
  # - num_layers: 決定要有幾個 EncoderLayers, 前面影片中的 `N`
  # - input_vocab_size: 用來把索引轉成詞嵌入向量
  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, 
                 maximum_position_encoding, rate=0.1):
    super(TransformerEncoderClassifier, self).__init__()    
    
    self.d_model = d_model
    # 注意 Encoder 已經包含了詞嵌入層 !!!
    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)
    self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)
    # 建立 `num_layers` 個 EncoderLayers
    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]
    self.dropout = tf.keras.layers.Dropout(rate)

    # 注意和一般完整的 Transformer 不同這邊我們還需要 layers to classify !!!
    # 這個 FFN 輸出跟我們 target class 一樣大的 logits 數，等通過 softmax 就代表每個 class 的出現機率 !!!
    self.final_layer = tf.keras.layers.Dense(2)
  
  def call(self, x, training, mask):
        # 輸入的 x.shape == (batch_size, input_seq_len)
        # 以下各 layer 的輸出皆為 (batch_size, input_seq_len, d_model)
        input_seq_len = tf.shape(x)[1]
        
        # 將 2 維的索引序列轉成 3 維的詞嵌入張量，並依照論文乘上 sqrt(d_model)
        # 再加上對應長度的位置編碼
        x = self.embedding(x)
        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
        x += self.pos_encoding[:, :input_seq_len, :]
        
        # 對 embedding 跟位置編碼的總合做 regularization
        # 這在 Decoder 也會做
        x = self.dropout(x, training=training)
        
        # 通過 N 個 EncoderLayer 做編碼
        for i, enc_layer in enumerate(self.enc_layers):
            x = enc_layer(x, training, mask)  # |outputs| : (batch_size, input_seq_len, d_model)
        
        # 注意這邊和一般完整的 Transformer 不同!!! 先將 EncoderLayer 的輸出延每個序列長度的方向取最大值
        x = tf.reduce_max(x, axis=[1])  # |outputs| : (batch_size, d_model)
        # 最後在通過一個 linear layer 讓輸出變成只有目標 class 數目
        final_output = self.final_layer(x)  # |outputs| : (batch_size, target_class_size)
        return tf.nn.softmax(final_output) # default softmax performed on the last dimension

model = TransformerEncoderClassifier(num_layers = args.n_layers,
                                           d_model = args.hidden,
                                           num_heads = args.n_attn_heads,
                                           dff = args.ffn_hidden,
                                           input_vocab_size = tokenizer.vocab_size,
                                           maximum_position_encoding = 3000
                                           rate = args.lr)

# Some Demo to lookup Dataset
fea_batch, tar_batch = next(iter(train_dataset))
enc_padding_mask = create_padding_mask(fea_batch)
for output, tarout in zip(model(fea_batch,True, enc_padding_mask), tar_batch):
  tf.print(output, tarout)

# 使用 cross entropy 來計算序列生成任務中實際的目標跟模型預測的目標分佈（distribution）相差有多遠
#loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')
loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=False)  #from_logits=False 因為 softmax 輸出是機率分佈
optimizer = tf.keras.optimizers.Adam(learning_rate=args.lr, beta_1=0.9, beta_2=0.98, epsilon=1e-9)
# 另外再定義兩個 tf.keras.metrics，方便之後使用 TensorBoard 來追蹤模型 performance：
train_loss = tf.keras.metrics.Mean(name='train_loss')
#train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')
train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')

# 一個數據集包含多個 batch，而每次拿一個 batch 來訓練的步驟就稱作 train_step
# 定義 Transformer 的每一個 train_step
@tf.function  # 讓 TensorFlow 幫我們將 eager code 優化並加快運算
def train_step(inp, tar):
    # 在序列生成任務裡頭，模型獲得的正確答案是輸入序列往左位移一個位置的結果 !!!
    # 訓練的時候並不是吃整個目標序列，而是吃一個去掉尾巴的序列 tar_inp，然後試著去預測「左移」一個字以後的序列 tar_real
    #tar_inp = tar[:, :-1]
    #tar_real = tar[:, 1:]
    tar_real = tar
    # 建立 3 個遮罩
    #enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)
    enc_padding_mask = create_padding_mask(inp)
    # 紀錄 Transformer 的所有運算過程以方便之後做梯度下降
    with tf.GradientTape() as tape:
        # 注意是丟入 `tar_inp` 而非 `tar`。記得將 `training` 參數設定為 True
        #predictions, _ = transformer(inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask)
        predictions = model(inp, True, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)
        # 跟影片中顯示的相同，計算左移一個字的序列跟模型預測分佈之間的差異，當作 loss
        #loss = loss_function(tar_real, predictions)
        loss = tf.reduce_mean(loss_object(tar_real, predictions))
        
    # 取出梯度並呼叫前面定義的 Adam optimizer 幫我們更新 Transformer 裡頭可訓練的參數
    gradients = tape.gradient(loss, model.trainable_variables)    
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))

    # 將 loss 以及訓練 acc 記錄到 TensorBoard 上，非必要
    train_loss(loss)
    train_accuracy(tar_real, predictions)

# Some Demo to lookup Train Step
#fea_batch, tar_batch = next(iter(train_dataset))
#train_step(fea_batch, tar_batch)

# 定義一些之後在儲存檔案時會用到的路徑變數
checkpoint_path = os.path.join("/content/gdrive/My Drive/Transformer", "checkpoints")
checkpoint_path = os.path.join(checkpoint_path, "Classification")

# tf.train.Checkpoint 可以幫我們把想要存下來的東西整合起來，方便儲存與讀取
# 一般來說你會想存下模型以及 optimizer 的狀態
ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)

# ckpt_manager 會去 checkpoint_path 看有沒有符合 ckpt 裡頭定義的東西
# 存檔的時候只保留最近 5 次 checkpoints，其他自動刪除
ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)

import time
last_epoch, EPOCHS = 0, 30
for epoch in range(last_epoch, EPOCHS):
    start = time.time()
    
    # 重置紀錄 TensorBoard 的 metrics
    train_loss.reset_states()
    train_accuracy.reset_states()
    
    # 一個 epoch 就是把我們定義的訓練資料集一個一個 batch 拿出來處理，直到看完整個數據集 
    for (step_idx, (inp, tar)) in enumerate(train_dataset):
        # 每次 step 就是將數據丟入 Transformer，讓它生預測結果並計算梯度最小化 loss
        #print('input:',inp.shape)
        #print('output:',tar.shape)
        #print('-'*20)
        train_step(inp, tar)
    
    # 每5個 epoch 完成就存一次檔    
    if (epoch + 1) % 5 == 0:
        ckpt_save_path = ckpt_manager.save()
        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))
    print('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, 
                                                train_loss.result(), 
                                                train_accuracy.result()))
    print('Time taken for 1 epoch: {} secs\n'.format(time.time() - start))

# Make input
text = 'I have to admit, I got so emotional all throughout the movie. \
        And some parts brought me to tears. The cast was phenomenal \
        and I think every superhero got to have their spotlight.'
tokens = tokenizer.tokenize(text)
input_ids = tokenizer.convert_tokens_to_ids(tokens)
padding_length = args.max_seq_len - len(input_ids)
input_ids = input_ids + ([tokenizer.pad_token_id] * padding_length)
print(len(input_ids))
input_ids = tf.expand_dims(input_ids, 0)
print(len(input_ids))
predictions = model(input_ids, False, create_padding_mask(input_ids))
print(predictions)