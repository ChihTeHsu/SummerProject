{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Setup plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "# Set Matplotlib defaults\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "red_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
        "\n",
        "# Create training and validation splits\n",
        "df_train = red_wine.sample(frac=0.7, random_state=0)\n",
        "df_valid = red_wine.drop(df_train.index)\n",
        "\n",
        "# Split features and target\n",
        "X_train = df_train.drop('quality', axis=1).to_numpy()\n",
        "X_valid = df_valid.drop('quality', axis=1).to_numpy()\n",
        "y_train = df_train['quality'].to_numpy()\n",
        "y_valid = df_valid['quality'].to_numpy()"
      ],
      "metadata": {
        "id": "1--87ajEQ7SG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jnu0O2cCJhGE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import tensorflow.experimental.numpy as tnp\n",
        "\n",
        "class BatchNormFCLayer(tf.keras.layers.Layer):  # for the case of fully connected (1D inputs)\n",
        "    \"\"\"\n",
        "    We create class variables such as gamma and beta to be trained. Also creating list of the accumulating\n",
        "    tensors of moving_mean and moving_variance that are expected to grow up to window size. They are helpful for the\n",
        "    last part of batchnorm algorithm where another affine transformation is performed using the averages\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, epsilon=0.00000001, window=5):\n",
        "        \"\"\"\n",
        "        :param epsilon:\n",
        "        :param window:\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        gamma_init = tf.ones_initializer()\n",
        "        self.gamma = tf.Variable(\n",
        "            initial_value=gamma_init(shape=[1], dtype='float32'), trainable=True)\n",
        "        beta_init = tf.zeros_initializer()\n",
        "        self.beta = tf.Variable(\n",
        "            initial_value=beta_init(shape=[1], dtype='float32'), trainable=True)\n",
        "        self.window = window\n",
        "        self.epsilon = epsilon\n",
        "        #self.moving_mean = []\n",
        "        #self.moving_variance = []\n",
        "        #self.moving_mean = tf.constant([])\n",
        "        #self.moving_variance = tf.constant([])\n",
        "        self.idx = 0\n",
        "        self.moving_mean = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
        "        self.moving_variance = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=False)\n",
        "\n",
        "    def call(self, inputs, training=False):  # Defines the computation from inputs to outputs\n",
        "        mu = tf.math.reduce_mean(inputs, axis=0)\n",
        "        variance = K.var(inputs, axis=0)\n",
        "        \n",
        "        #outputs = batchnorm_calculations(self, mu, variance, inputs, training)\n",
        "        \n",
        "        if training:  # In case of training, perform batch normalization to learn beta and gamma\n",
        "            x_hat = (inputs - mu) / K.sqrt(variance + self.epsilon)\n",
        "            outputs = self.gamma * x_hat + self.beta\n",
        "        else:  # In case of testing - calculation of the inference model\n",
        "            #self.moving_mean.append(mu)\n",
        "            #self.moving_variance.append(variance)\n",
        "            #self.moving_mean = tf.concat([self.moving_mean, mu], 1)\n",
        "            #self.moving_variance = tf.concat([self.moving_variance, variance], 1)\n",
        "            self.moving_mean = self.moving_mean.write(self.idx, mu)\n",
        "            self.moving_variance = self.moving_variance.write(self.idx, variance)\n",
        "            self.idx = self.idx + 1\n",
        "\n",
        "            #if len(self.moving_mean) > self.window:  # keep the scope of the window\n",
        "            if self.idx == self.window:  # keep the scope of the window\n",
        "                #self.moving_mean = self.moving_mean[1:]\n",
        "                #self.moving_variance = self.moving_variance[1:]\n",
        "                self.idx = 0\n",
        "            #tf.print(self.moving_mean.stack(), self.idx, self.window)\n",
        "\n",
        "            #if len(self.moving_mean) == 1:  # In case this is the first batch, than the average will be itself\n",
        "            if self.idx == 1:  # In case this is the first batch, than the average will be itself\n",
        "                current_mean_means = mu\n",
        "                current_mean_variances = variance\n",
        "            else:  # In the regular case we calculate the mean and variance according to the given in the paper\n",
        "                #tf.print(self.moving_mean.stack())\n",
        "                #current_mean_means = tf.keras.layers.Average()(self.moving_mean.stack())\n",
        "                current_mean_means = tf.math.reduce_mean(self.moving_mean.stack(), axis=0)\n",
        "\n",
        "                # tf.shape()[0], can return a dynamic scalar tensor pointing to inputs' actual batch size. But it return int32\n",
        "                dim = tf.cast(tf.shape(inputs)[0], dtype=tf.float32) # inputs.shape[0]\n",
        "                # K.mean() makes 'ListWrapper' object has no attribute 'dtype' error\n",
        "                # the solution is to use: K.mean(tf.stack(curr_layer.moving_variance), axis=0)\n",
        "                #testalpha = tf.keras.layers.Average()(self.moving_variance)\n",
        "                testalpha = tf.math.reduce_mean(self.moving_variance.stack(), axis=0)\n",
        "                current_mean_variances = dim / (dim - 1) * testalpha\n",
        "\n",
        "            outputs = self.gamma / K.sqrt(current_mean_variances + self.epsilon) * inputs + \\\n",
        "                      (self.beta - self.gamma * current_mean_means / K.sqrt(current_mean_variances +\n",
        "                                                                                        self.epsilon))\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bn = BatchNormFCLayer(window=3)\n",
        "inp = bn(X_train[:4,:],training=False)\n",
        "#print(inp)\n",
        "\n",
        "inp = bn(X_train[4:8,:],training=False)\n",
        "#print(inp)\n",
        "\n",
        "inp = bn(X_train[8:12,:],training=False)\n",
        "#print(inp)\n",
        "\n",
        "inp = bn(X_train[12:16,:],training=False)\n",
        "#print(inp)\n",
        "\n",
        "inp = bn(X_train[16:20,:],training=False)\n",
        "#print(inp)\n",
        "\n",
        "inp = bn(X_train[20:24,:],training=False)\n",
        "#print(inp)\n",
        "\n",
        "inp = bn(X_train[24:28,:],training=False)\n",
        "#print(inp)"
      ],
      "metadata": {
        "id": "F9ty_dpFN3yq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = tf.constant([ ])\n",
        "B = tf.constant([0.1])\n",
        "out = tf.concat([A, B], 0)\n",
        "C = tf.constant([0.2])\n",
        "out = tf.concat([out, C], 0)\n",
        "print(out) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v9fAZGRNGCi",
        "outputId": "a07170cf-1101-4819-fe49-de9728836a12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0.1 0.2], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(32, activation='relu', input_shape=[11]),\n",
        "    #layers.Dropout(0.3),\n",
        "    BatchNormFCLayer(),\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    #layers.Dropout(0.3),\n",
        "    #BatchNormFCLayer(),\n",
        "    #layers.Dense(1024, activation='relu'),\n",
        "    #layers.Dropout(0.3),\n",
        "    #BatchNormFCLayer(),\n",
        "    layers.Dense(1),\n",
        "])"
      ],
      "metadata": {
        "id": "4iaZW3Yzqgcb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mae',\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=256,\n",
        "    epochs=100,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "\n",
        "# Show the learning curves\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.loc[:, ['loss', 'val_loss']].plot();"
      ],
      "metadata": {
        "id": "yzfYfEr_qgTO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7dd2f4fe-25cb-46d5-b61a-46aa1359745a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ba86a26cc9b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: <tf.Tensor 'batch_norm_fc_layer_1/Mean:0' shape=(32,) dtype=float32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.\nPlease see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\n\n<tf.Tensor 'batch_norm_fc_layer_1/Mean:0' shape=(32,) dtype=float32> was defined here:\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1233, in inner\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1147, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n      user_expressions, allow_stdin,\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-5-172138891bc5>\", line 14, in <module>\n      layers.Dense(1),\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 587, in _method_wrapper\n      result = method(self, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\", line 136, in __init__\n      self.add(layer)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\", line 587, in _method_wrapper\n      result = method(self, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\", line 220, in add\n      output_tensor = layer(self.outputs[0])\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 945, in __call__\n      input_list)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 2316, in _functional_construction_call\n      inputs, input_masks, args, kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 2186, in _keras_tensor_symbolic_call\n      return self._infer_output_signature(inputs, args, kwargs, input_masks)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 2232, in _infer_output_signature\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"<ipython-input-2-6c09a27fc7a4>\", line 38, in call\n      mu = tf.math.reduce_mean(inputs, axis=0)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\", line 1082, in op_dispatch_handler\n      return dispatch_target(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 2641, in reduce_mean\n      name=name))\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 6288, in mean\n      name=name)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 799, in _apply_op_helper\n      attrs=attr_protos, op_def=op_def)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 696, in _create_op_internal\n      compute_device)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3762, in _create_op_internal\n      op_def=op_def)\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2133, in __init__\n      self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n\nThe tensor <tf.Tensor 'batch_norm_fc_layer_1/Mean:0' shape=(32,) dtype=float32> cannot be accessed from here, because it was defined in FuncGraph(name=batch_norm_fc_layer_1_scratch_graph, id=139815566762768), which is out of scope."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "inp = np.array([[[1., 1., 1., 1.],\n",
        "                [1., 1., 1., 1.],\n",
        "                [1., 1., 1., 1.]],\n",
        "               [[1., 2., 3., 4.],\n",
        "                [1., 2., 3., 4.],\n",
        "                [1., 2., 3., 4.]]])"
      ],
      "metadata": {
        "id": "MzMXjkTqZyEa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}